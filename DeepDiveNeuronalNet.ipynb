{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Documentation Neuronal Network\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# We will use this cell to import all the packages you will need in the following - think of it as turning on all your systems\n","# in your cockpit\n","\n","# This makes sure that if you change code in your external scripts, they will be updated\n","\n","from IPython.display import display, clear_output\n","import numpy as np\n","import time\n","import math\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","import pandas as pd\n","from tensorflow import keras\n","from keras.api._v2.keras import layers\n","import tensorflow as tf\n","import os\n","from keras.regularizers import l2\n","from keras.preprocessing.image import ImageDataGenerator\n","import datetime\n","import umap\n","\n","cwd = os.getcwd ()\n","\n","# now go ahead and Run the cell. This might take a while...\n","# while the cell is running, you will see ln[*] next to it. Once it finished, you will see the number of execution\n","# In case you want to interrupt the run of a cell, press Ctrl + C (on your german keyboard, this is Strg + C) \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Loading the MNIST Dataset\n","\n","To build and train our model we need to load the MNIST dataset. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Loading the MNIST dataset in one line\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","# Printing the shape\n","print('x_train:', x_train.shape)\n","print('y_train:', y_train.shape)\n","print('x_test:', x_test.shape)\n","print('y_test:', y_test.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Defining our function to calculate the mse of two pictures\n","\n","With this function we want to calculate the mse of two labels to get the most similar ones\n"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["def calculate_mse(imageA, imageB):\n","\t# the 'Mean Squared Error' between the two images is the\n","\t# sum of the squared difference between the two images;\n","\t# NOTE: the two images must have the same dimension\n","\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n","\terr /= float(imageA.shape[0] * imageA.shape[1])\n","\t\n","\t# return the MSE, the lower the error, the more \"similar\"\n","\t# the two images are\n","\treturn err"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining our function to search the best images\n","\n","The function calculates the mse of all images of one number. \n","We get the 10 best representing labels of the dataset to train our model with only 10 labels.  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["'''keep_numbers=[]\n","mse_numbers = []\n","def searchBestImage():\n","  for number in range (0,10):\n","    mse_number = 0.0\n","    filter_for_number = np.where(y_train == number)[0]\n","    for number1 in range (len(filter_for_number)):\n","      for number2 in range (len(filter_for_number)):\n","        mse_number += calculate_mse(x_train[filter_for_number[number1]],x_train[filter_for_number[number2]])\n","      mse_number = mse_number / len(filter_for_number)\n","      mse_numbers.append(mse_number)\n","    min = np.argmin(mse_numbers)\n","    keep_index.append(filter_for_number[min])\n","    mse_numbers.clear()\n","    filter_for_number = np.where(y_train == number )[0]\n","\n","\n","x_train = x_train[0:5000]\n","y_train = y_train[0:5000]\n","\n","def search_for_most_similar_input(list, index):\n","  store_mse = 1.0\n","  remember_index = 1\n","  for i in range (index, len(list)):\n","    if i != index: \n","      actual_mse = calculate_mse(list[index], list[i])\n","      if actual_mse < store_mse:\n","        store_mse = actual_mse\n","        remember_index = i\n","  return remember_index\n","for calc in range (0,5):\n","  for i in range (0,10):\n","    filter_for_number = np.where(y_train == i)[0]\n","    for y in range (len(x_train[filter_for_number])//2):\n","      index = search_for_most_similar_input(x_train[filter_for_number], y)\n","      x_train = np.delete(x_train, filter_for_number[index], 0)\n","      y_train = np.delete(y_train,filter_for_number[index])\n","      filter_for_number = np.where(y_train == i )[0]\n","'''\n","keep_index = [39306, 45926, 35779, 9059, 3639, 29049, 15459, 26151, 56284, 1733]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Reshaping the training data\n","\n","Before we can start defining and training our model we need to prepare our training dataset. \n","Therefore we need to reshape the training and validation data to fit our input layer. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_train = x_train/255\n","x_test = x_test/255\n","\n","# in the next step, we also need to reshape our input to fit our input layer later on. \n","# This is due to keras expecting a definition for how many channels your input sample has, as we \n","# deal with gray scale this is 1.\n","\n","x_train= x_train.reshape(-1, 784)\n","x_test = x_test.reshape(-1, 784)\n","'''\n","x_train = x_train.astype(\"float32\") / 255\n","x_test = x_test.astype(\"float32\") / 255\n","# Make sure images have shape (28, 28, 1)\n","x_train = np.expand_dims(x_train, -1)\n","x_test = np.expand_dims(x_test, -1)\n","print(\"x_train shape: \", x_train.shape)\n","print(\"y_train shape: \", y_train.shape)\n","print(\"x_test shape\", x_test.shape)\n","print(\"y_test shape\", y_test.shape)\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)'''"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining an ImageDataGenerator"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(\n","            featurewise_center=False,  # set input mean to 0 over the dataset\n","            samplewise_center=False,  # set each sample mean to 0\n","            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","            samplewise_std_normalization=False,  # divide each input by its std\n","            zca_whitening=False,  # apply ZCA whitening\n","            rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","            zoom_range = 0.1, # Randomly zoom image \n","            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","            horizontal_flip=False,  # randomly flip images\n","            vertical_flip=False)  # randomly flip images"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining UMAP Model\n","\n","To get better results and predictions of our model we use the umap Model and transform our training data. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["n_components=10\n","umap_model = umap.UMAP(n_components=n_components )\n","x_train_reduced = umap_model.fit_transform(x_train)\n","x_test_reduced = umap_model.transform(x_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Print out the training data \n","\n","Before training we want to have a look at the training data and the shape of the dataset. "]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["y_train: [0 1 2 3 4 5 6 7 8 9]\n","x_red: (10, 784)\n"]}],"source":["x_train_reduced=x_train_reduced[keep_index]\n","y_train=y_train[keep_index]\n","print(\"y_train:\",y_train)\n","print('x_red:', x_train.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining our Model\n","\n","Now we can define our model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["marvin = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(n_components,)),\n","  tf.keras.layers.Dense(256, activation='sigmoid',kernel_initializer='glorot_uniform'),\n","  tf.keras.layers.Dropout(0.1),\n","  tf.keras.layers.Dense(10, activation='softmax',kernel_initializer='glorot_uniform', use_bias=True)\n","])\n","marvin.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["marvin.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n","              loss= 'sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining model parameters and early stopping. \n","\n","We define early stopping, the reduce learnrate and the modelcheckpoints to use them later while training. "]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","#%%\n","early_stopping = tf.keras.callbacks.EarlyStopping (monitor='val_accuracy',patience=15,mode=\"max\") \n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau (monitor ='val_accuracy', factor =0.5 , min_delta=0.00005 , \n","                                                  patience=6, min_lr=0.0001, mode=\"max\")\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint (filepath=os.path.join(cwd,'models/DNN_UMAP_30.h5'),\n","                                                       monitor='val_accuracy',save_best_only=True, mode=\"max\")\n","#%%"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fit Model\n","\n","We train the model with our training dataset and the model parameters we defined. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["marvin.fit(\n","    x_train_reduced,\n","    y_train,\n","    epochs= 200,\n","    batch_size= 32,\n","    validation_data=(x_test_reduced, y_test),\n","    callbacks=[model_checkpoint,reduce_lr]\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Safe Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#SAVE MODEL \n","model_name = 'model_1'\n","marvin.save(model_name, save_format='h5')\n","\n","print('Success! You saved Marvin as: ', model_name)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#%% EVALUATE MODEL (just to be sure the last val acc value was right)\n","marvin_reloaded = tf.keras.models.load_model('models/DNN_UMAP_30.h5')\n","marvin_reloaded.summary()\n","loss_and_metrics = marvin_reloaded.evaluate(x_test_reduced, y_test, verbose=2)\n","\n","print(\"Test Loss\", loss_and_metrics[0])\n","print(\"Test Accuracy\", loss_and_metrics[1])\n","\n","#%%\n","\n","# Let Marvin predict on the test set, so we have some data to evaluate his performance.\n","predictions = marvin_reloaded.predict([x_test_reduced])\n","\n","# Remember that the prediction of Marvin is a probability distribution over all ten-digit classes\n","# We want him to assign the digit class with the highest probability to the sample.\n","predictions = np.argmax(predictions, axis=1)\n","#pd.DataFrame(predictions)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":4}
