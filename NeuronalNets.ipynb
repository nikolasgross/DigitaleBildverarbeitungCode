{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Neuronal Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We will use this cell to import all the packages you will need in the following - think of it as turning on all your systems\n",
    "# in your cockpit\n",
    "\n",
    "# This makes sure that if you change code in your external scripts, they will be updated\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.api._v2.keras import layers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import datetime\n",
    "import umap\n",
    "\n",
    "cwd = os.getcwd ()\n",
    "\n",
    "# now go ahead and Run the cell. This might take a while...\n",
    "# while the cell is running, you will see ln[*] next to it. Once it finished, you will see the number of execution\n",
    "# In case you want to interrupt the run of a cell, press Ctrl + C (on your german keyboard, this is Strg + C) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Defining the model and data parameters\n",
    "\n",
    "Now we define our parameters to use them later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "keep_index = [39306, 45926, 35779, 9059, 3639, 29049, 15459, 26151, 56284, 1733]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the MNIST dataset\n",
    "\n",
    "Before any data science or machine learning project, it is essential to get to know your data. This will enable you to detect issues, noise, pitfalls and understand what your model will learn at the end of the day. With the MNIST dataset, you will be working with a beautiful, cleaned, easy to understand, low-memory, large-scale dataset. \n",
    "Full disclaimer, MNIST is excellent for learning and research purposes, yet this is not what you can expect in real-life. \n",
    "\n",
    "This initially becomes obvious as MNIST is so commonly used that the Keras packages got our back with loading the data in one line. We are loading pairs of samples and ground truth annotations for both the training set (for training our model) and the test set (for testing our model). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset in one line\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Printing the shape\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our function to calculate the mse of two pictures\n",
    "\n",
    "With this function we want to calculate the mse of two labels to get the most similar ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(imageA, imageB):\n",
    "\t# the 'Mean Squared Error' between the two images is the\n",
    "\t# sum of the squared difference between the two images;\n",
    "\t# NOTE: the two images must have the same dimension\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\t\n",
    "\t# return the MSE, the lower the error, the more \"similar\"\n",
    "\t# the two images are\n",
    "\treturn err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''keep_numbers=[]\n",
    "mse_numbers = []\n",
    "def searchBestImage():\n",
    "  for number in range (0,10):\n",
    "    mse_number = 0.0\n",
    "    filter_for_number = np.where(y_train == number)[0]\n",
    "    for number1 in range (len(filter_for_number)):\n",
    "      for number2 in range (len(filter_for_number)):\n",
    "        mse_number += calculate_mse(x_train[filter_for_number[number1]],x_train[filter_for_number[number2]])\n",
    "      mse_number = mse_number / len(filter_for_number)\n",
    "      mse_numbers.append(mse_number)\n",
    "    min = np.argmin(mse_numbers)\n",
    "    keep_index.append(filter_for_number[min])\n",
    "    mse_numbers.clear()\n",
    "    filter_for_number = np.where(y_train == number )[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# in the next step, we also need to reshape our input to fit our input layer later on. \n",
    "# This is due to keras expecting a definition for how many channels your input sample has, as we \n",
    "# deal with gray scale this is 1.\n",
    "\n",
    "x_train= x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=8\n",
    "umap_model = umap.UMAP(n_components=n_components,)\n",
    "x_train_reduced = umap_model.fit_transform(x_train)\n",
    "x_test_reduced = umap_model.transform(x_test)\n",
    "#print(\"Number of input:\",lda.n_components_)\n",
    "keep_index = [39306, 45926, 35779, 9059, 3639, 15459, 26151, 56284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reduced=x_train_reduced[keep_index]\n",
    "y_train=y_train[keep_index]\n",
    "print(\"y_train:\",y_train)\n",
    "print('x_red:', x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(n_components,)),\n",
    "  tf.keras.layers.Dense(256, activation='sigmoid',kernel_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(128, activation='sigmoid',kernel_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.Dropout(0.1),#\n",
    "  tf.keras.layers.Dense(10, activation='softmax',kernel_initializer='glorot_uniform', use_bias=True)\n",
    "])\n",
    "marvin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss= 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "#%%\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping (monitor='val_accuracy',patience=15,mode=\"max\") \n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau (monitor ='val_accuracy', factor =0.5 , min_delta=0.00005 , \n",
    "                                                  patience=6, min_lr=0.0001, mode=\"max\")\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint (filepath=os.path.join(cwd,'models/DNN_UMAP_30.h5'),\n",
    "                                                       monitor='val_accuracy',save_best_only=True, mode=\"max\")\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marvin.fit(\n",
    "    x_train_reduced,\n",
    "    y_train,\n",
    "    epochs= 200,\n",
    "    batch_size= 32,\n",
    "    validation_data=(x_test_reduced, y_test),\n",
    "    callbacks=[model_checkpoint,reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE MODEL \n",
    "model_name = 'model_1'\n",
    "marvin.save(model_name, save_format='h5')\n",
    "\n",
    "print('Success! You saved Marvin as: ', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% EVALUATE MODEL (just to be sure the last val acc value was right)\n",
    "marvin_reloaded = tf.keras.models.load_model('models/DNN_UMAP_30.h5')\n",
    "marvin_reloaded.summary()\n",
    "loss_and_metrics = marvin_reloaded.evaluate(x_test_reduced, y_test, verbose=2)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])\n",
    "\n",
    "#%%\n",
    "\n",
    "# Let Marvin predict on the test set, so we have some data to evaluate his performance.\n",
    "predictions = marvin_reloaded.predict([x_test_reduced])\n",
    "\n",
    "# Remember that the prediction of Marvin is a probability distribution over all ten-digit classes\n",
    "# We want him to assign the digit class with the highest probability to the sample.\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "#pd.DataFrame(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
